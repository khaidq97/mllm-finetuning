# Gemma 3 Projector Training Configuration
# ===========================================

model:
  model_path: "models/gemma3-4b-it"
  torch_dtype: "bfloat16"
  device_map: "auto"
  use_flash_attention: true
  
  # Freeze settings - only train projector by default
  freeze_vision_encoder: true
  freeze_text_model: true
  train_projector: true

data:
  train_data_path: "dataset/train.json"
  val_data_path: null  # Optional: "dataset/val.json"
  image_root: "dataset/images"
  max_length: 2048
  num_workers: 4

training:
  output_dir: "outputs/projector_v1"
  num_epochs: 3
  batch_size: 2
  gradient_accumulation_steps: 8  # Effective batch size = 16
  
  # Optimizer
  learning_rate: 1.0e-4
  weight_decay: 0.01
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  
  # Scheduler
  lr_scheduler: "cosine"
  
  # Logging and checkpointing
  logging_steps: 10
  save_steps: 500
  eval_steps: 500
  save_total_limit: 3
  
  # Mixed precision
  bf16: true
  fp16: false
  
  # Memory optimization
  gradient_checkpointing: true
  
  # Reproducibility
  seed: 42

